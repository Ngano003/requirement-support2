# 要件定義書レビュー PoC 設計

## 1. 概要
本PoCは、要件定義書（Markdown形式）に対して、`doc/defect_taxonomy.md` で定義された5つの観点に基づく自動レビューを行い、**ヌケ・モレ・矛盾**を検出するスクリプトを作成・検証することを目的とする。

## 2. 全体処理フロー

```
┌─────────────────────────────────────────────────────────────────────┐
│                        入力: 要件定義書                              │
└─────────────────────────────────────────────────────────────────────┘
                                  │
                                  ▼
┌─────────────────────────────────────────────────────────────────────┐
│ [前処理] Section-wise Split                                         │
│   効果: Lost in the Middle問題を回避し、長文でも漏れなく分析        │
└─────────────────────────────────────────────────────────────────────┘
                                  │
                    ┌─────────────┼─────────────┐
                    ▼             ▼             ▼
              [Section 1]   [Section 2]   [Section N]
                    │             │             │
                    └─────────────┼─────────────┘
                                  │
        ┌─────────────────────────┼─────────────────────────┐
        ▼                         ▼                         ▼
   [観点1: Dead Ends]      [観点2: Missing Else]     ... [観点5]
        │                         │                         │
        └─────────────────────────┼─────────────────────────┘
                                  │
                    ┌─────────────┴─────────────┐
                    ▼                           ▼
        ┌───────────────────┐       ┌───────────────────┐
        │ Step 1: Scan      │       │ Step 1: Scan      │
        │ (Multi-Pass)      │       │ (Multi-Pass)      │
        └───────────────────┘       └───────────────────┘
                    │                           │
                    ▼                           ▼
        ┌───────────────────┐       ┌───────────────────┐
        │ Step 2: Grounding │       │ Step 2: Grounding │
        └───────────────────┘       └───────────────────┘
                    │                           │
                    ▼                           ▼
        ┌───────────────────┐       ┌───────────────────┐
        │ Step 3: Falsify   │       │ Step 3: Falsify   │
        └───────────────────┘       └───────────────────┘
                    │                           │
                    └─────────────┬─────────────┘
                                  ▼
┌─────────────────────────────────────────────────────────────────────┐
│ [後処理] Cross-Reference Check                                      │
│   効果: 観点間の相互作用を分析し、根本原因を特定                    │
└─────────────────────────────────────────────────────────────────────┘
                                  │
                                  ▼
┌─────────────────────────────────────────────────────────────────────┐
│                        出力: 欠陥レポート                            │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 3. 各ステップの詳細と効果

### [前処理] Section-wise Split (セクション分割)

| 項目 | 内容 |
| :--- | :--- |
| **目的** | 長文ドキュメントでの見落としを防ぐ |
| **課題** | LLMは長いコンテキストの中間部分への注意が弱まる（**Lost in the Middle問題**） |
| **対策** | 要件定義書をMarkdownの見出し(`##`)単位でセクション分割し、各セクションに対して独立にレビューを実行 |
| **期待効果** | **Recall +15〜20%** (長文での見落とし削減) |

**重要: 要約ではなく分割**
- 各セクションの**原文をそのまま**LLMに渡す（要約すると情報が欠落するリスクがあるため）
- 分割単位の推奨: まず `##` (見出しレベル2) で分割し、長すぎる場合は `###` に細分化

**セクション間参照の問題と解決策**:
```
【問題例】
Section 1 (共通仕様): 「すべてのモーターは目的達成後に自動停止する」
Section 3 (制御ルール): 「移動開始時にメインモーターを回転させる」
→ Section 3だけ見ると「停止条件がない」と誤検知される
```

| Step | 入力範囲 | 役割 |
| :--- | :--- | :--- |
| Step 1 (Scan) | **セクション単位** | 漏れなく候補を洗い出す (Recall重視) |
| Step 2 (Grounding) | **全文** | 幻覚を排除 |
| Step 3 (Falsification) | **全文** | **他セクションでの定義を確認し、誤検知を排除** |

→ Step 1でセクション単位に候補を抽出し、Step 3で全文を見て「実は別セクションで定義されていた」と判断させる設計。

**実装イメージ**:
```python
sections = split_by_heading(document, level=2)  # ##で分割

# Step 1: セクション単位でスキャン
all_candidates = []
for section in sections:
    candidates = scan(section, viewpoint)
    all_candidates.extend(candidates)

# Step 2-3: 全文で検証・反証
for candidate in all_candidates:
    grounded = ground(full_document, candidate)    # 全文で引用確認
    if grounded:
        result = falsify(full_document, candidate)  # 全文で反証
```

---

### Step 1: Scan (構造抽出・初期レビュー) - Multi-Pass方式

| 項目 | 内容 |
| :--- | :--- |
| **目的** | 観点に関連する要素を**網羅的に**抽出する |
| **課題** | 1回の問いかけでは、LLMは「見つけやすいもの」だけ返して満足してしまう（**Early Exit問題**） |
| **対策** | 同じ観点に対して**2回（Pass 1 + Pass 2）**抽出を実行し、結果をマージ |
| **期待効果** | **Recall +10〜15%** (見落とし削減) |

**Prompt設計** (Few-Shot Examples付き):

```
【観点】Missing Else (条件の網羅漏れ)
【定義】条件分岐において、True側の処理はあるがFalse/Else側の処理が未定義。

【良い例 (OK)】
  記述: 「温度 > 50℃ならファンON、そうでなければファンOFF」
  判定: OK (else定義あり)

【悪い例 (Defect)】
  記述: 「温度 > 50℃ならファンをON」
  判定: Defect (50℃以下の場合が未定義)

【タスク】
以下の要件定義書から、条件分岐と思われる箇所を**すべて**抽出し、
それぞれについて else/default の記述があるか判定せよ。

{section_text}
```

**Output形式**:
```json
[
  { "id": "chk_1", "target_text": "...", "status": "Suspected", "reason": "..." },
  { "id": "chk_2", "target_text": "...", "status": "OK", "reason": "..." }
]
```

---

### Step 2: Grounding (根拠確認)

| 項目 | 内容 |
| :--- | :--- |
| **目的** | LLMの幻覚（Hallucination）を排除する |
| **課題** | LLMは存在しない記述を「ある」と思い込んだり、逆に存在する記述を無視したりする |
| **対策** | 指摘の根拠となる**原文の引用**を強制する。引用できない指摘は破棄 |
| **期待効果** | **Precision +20〜30%** (誤検知削減) |

**Prompt設計**:
```
あなたは以下の指摘を行いました:
「{reason}」

この指摘の根拠となる記述を、要件定義書から**一字一句変えずに**引用してください。
引用が見つからない場合、この指摘は無効として取り下げてください。

{full_document}
```

**Output形式**:
```json
{
  "id": "chk_1",
  "is_grounded": true,
  "quote": "持ち上げる対象の重量が 5kg 以上の場合、アームの出力を「強」にする。"
}
```

---

### Step 3: Falsification (反証)

| 項目 | 内容 |
| :--- | :--- |
| **目的** | 文脈の読み違いによる誤検知を排除する |
| **課題** | 局所的には欠陥に見えても、別のセクション（共通仕様、前提条件など）でカバーされている場合がある |
| **対策** | 「指摘は間違っている」という前提で、反証材料を探させる（**Devil's Advocate**） |
| **期待効果** | **Precision +15〜25%** (文脈誤読による誤検知削減) |

**Prompt設計**:
```
あなたは「{defect_summary}」という欠陥を指摘しました。

しかし、この指摘は**間違っている可能性**があります。
要件定義書全体（特に共通仕様、前提条件、エラーハンドリング規定）をもう一度確認し、
このケースが**実は定義されている**可能性がないか調べてください。

指摘を覆す根拠があれば提示し、指摘を無効化してください。
根拠が見つからなければ、指摘は有効として確定してください。

{full_document}
```

**Output形式**:
```json
{
  "id": "chk_1",
  "is_valid": true,
  "final_reason": "共通仕様にも重量に関するデフォルト動作の規定は見当たらないため、指摘は有効。"
}
```

---

### [後処理] Cross-Reference Check (相互参照分析)

| 項目 | 内容 |
| :--- | :--- |
| **目的** | 欠陥間の関連性を分析し、根本原因を特定する |
| **課題** | 観点ごとに独立してレビューすると、「Dead EndがOrphan Stateも引き起こしている」などの相互作用を見落とす |
| **対策** | 検出された欠陥リストを統合し、LLMに関連性を分析させる |
| **期待効果** | **根本原因の特定**、**レポートの質向上** |

**Prompt設計**:
```
以下の欠陥が検出されました:
{defect_list}

これらの欠陥間に関連性はありますか？
例えば、ある欠陥が別の欠陥の原因になっている、または同じ設計上の見落としに起因している、など。

関連性がある場合、グループ化して根本原因を説明してください。
```

---

## 4. 観点定義 (5つの検出対象)

| No | 観点 | 抽出対象 | チェック内容 |
| :--- | :--- | :--- | :--- |
| 1 | Dead Ends | 全「状態(State)」 | 遷移先(Outgoing Edge)が0個か？ |
| 2 | Missing Else | 全「条件分岐(Conditions)」 | False/Else時の挙動記述があるか？ |
| 3 | Orphan States | 全「状態(State)」 | 遷移元(Incoming Edge)が0個か？ |
| 4 | Conflicting Outputs | 同一トリガーで発生する「出力/アクション」のペア | 論理的に両立不能な組み合わせか？ |
| 5 | Unstated Side Effects | 「開始(Start)」アクションを持つ処理 | 対応する「終了(Stop/End)」アクションがあるか？ |

---

## 5. 効果まとめ

| 工夫 | 対象メトリクス | 期待効果 | 実装コスト |
| :--- | :--- | :--- | :--- |
| Section-wise Split | Recall | +15〜20% | 中 |
| Multi-Pass Extraction | Recall | +10〜15% | 低 |
| Few-Shot Examples | Recall & Precision | +10〜15% | 低 |
| Grounding (引用強制) | Precision | +20〜30% | 低 |
| Falsification (反証) | Precision | +15〜25% | 低 |
| Cross-Reference Check | レポート品質 | 根本原因特定 | 中 |

---

## 6. 使用コンポーネント
- **LLM Gateway**: `src/infrastructure/llm_gateway.py`
- **Core Script**: `poc/review_poc.py`
